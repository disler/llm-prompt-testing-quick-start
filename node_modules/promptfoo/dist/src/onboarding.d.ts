export declare const DEFAULT_PROMPTS = "Your first prompt goes here\n---\nNext prompt goes here. You can substitute variables like this: {{var1}} {{var2}} {{var3}}\n---\nThis is the next prompt.\n\nThese prompts are nunjucks templates, so you can use logic like this:\n{% if var1 %}\n  {{ var1 }}\n{% endif %}\n---\n[\n  {\"role\": \"system\", \"content\": \"This is another prompt. JSON is supported.\"},\n  {\"role\": \"user\", \"content\": \"Using this format, you may construct multi-shot OpenAI prompts\"}\n  {\"role\": \"user\", \"content\": \"Variable substitution still works: {{ var3 }}\"}\n]\n---\nIf you prefer, you can break prompts into multiple files (make sure to edit promptfooconfig.yaml accordingly)\n";
export declare const DEFAULT_YAML_CONFIG = "# This configuration compares LLM output of 2 prompts x 2 GPT models across 3 test cases.\n# Learn more: https://promptfoo.dev/docs/configuration/guide\ndescription: 'My first eval'\n\nprompts:\n  - \"Write a tweet about {{topic}}\"\n  - \"Write a very concise, funny tweet about {{topic}}\"\n\nproviders: [openai:gpt-3.5-turbo-0613, openai:gpt-4]\n\ntests:\n  - vars:\n      topic: bananas\n\n  - vars:\n      topic: avocado toast\n    assert:\n      # For more information on assertions, see https://promptfoo.dev/docs/configuration/expected-outputs\n      - type: icontains\n        value: avocado\n      - type: javascript\n        value: 1 / (output.length + 1)  # prefer shorter outputs\n\n  - vars:\n      topic: new york city\n    assert:\n      # For more information on model-graded evals, see https://promptfoo.dev/docs/configuration/expected-outputs/model-graded\n      - type: llm-rubric\n        value: ensure that the output is funny\n";
export declare const DEFAULT_README = "To get started, set your OPENAI_API_KEY environment variable.\n\nNext, edit promptfooconfig.yaml.\n\nThen run:\n```\npromptfoo eval\n```\n\nAfterwards, you can view the results by running `promptfoo view`\n";
//# sourceMappingURL=onboarding.d.ts.map