"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.AzureOpenAiChatCompletionProvider = exports.AzureOpenAiCompletionProvider = exports.AzureOpenAiEmbeddingProvider = void 0;
const logger_1 = __importDefault(require("../logger"));
const shared_1 = require("./shared");
const cache_1 = require("../cache");
class AzureOpenAiGenericProvider {
    constructor(deploymentName, options = {}) {
        const { config, id, env } = options;
        this.deploymentName = deploymentName;
        this.apiHost =
            config?.apiHost || env?.AZURE_OPENAI_API_HOST || process.env.AZURE_OPENAI_API_HOST;
        this.apiBaseUrl =
            config?.apiBaseUrl || env?.AZURE_OPENAI_API_BASE_URL || process.env.AZURE_OPENAI_API_BASE_URL;
        this.config = config || {};
        this.id = id ? () => id : this.id;
    }
    async getApiKey() {
        if (!this._cachedApiKey) {
            if (this.config?.azureClientSecret &&
                this.config?.azureClientId &&
                this.config?.azureTenantId) {
                const { ClientSecretCredential } = await Promise.resolve().then(() => __importStar(require('@azure/identity')));
                const credential = new ClientSecretCredential(this.config.azureTenantId, this.config.azureClientId, this.config.azureClientSecret, {
                    authorityHost: this.config.azureAuthorityHost || 'https://login.microsoftonline.com',
                });
                this._cachedApiKey = (await credential.getToken(this.config.azureTokenScope || 'https://cognitiveservices.azure.com/.default')).token;
            }
            else {
                this._cachedApiKey = this.config?.apiKey || process.env.AZURE_OPENAI_API_KEY;
                if (!this._cachedApiKey) {
                    throw new Error('Azure OpenAI API key must be set');
                }
            }
        }
        return this._cachedApiKey;
    }
    getApiBaseUrl() {
        return this.apiBaseUrl || `https://${this.apiHost}`;
    }
    id() {
        return `azureopenai:${this.deploymentName}`;
    }
    toString() {
        return `[Azure OpenAI Provider ${this.deploymentName}]`;
    }
    // @ts-ignore: Params are not used in this implementation
    async callApi(prompt, context, callApiOptions) {
        throw new Error('Not implemented');
    }
}
class AzureOpenAiEmbeddingProvider extends AzureOpenAiGenericProvider {
    async callEmbeddingApi(text) {
        const apiKey = await this.getApiKey();
        if (!apiKey) {
            throw new Error('Azure OpenAI API key must be set for similarity comparison');
        }
        if (!this.getApiBaseUrl()) {
            throw new Error('Azure OpenAI API host must be set');
        }
        const body = {
            input: text,
            model: this.deploymentName,
        };
        let data, cached = false;
        try {
            ({ data, cached } = (await (0, cache_1.fetchWithCache)(`${this.getApiBaseUrl()}/openai/deployments/${this.deploymentName}/embeddings?api-version=${this.config.apiVersion || '2023-12-01-preview'}`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'api-key': apiKey,
                },
                body: JSON.stringify(body),
            }, shared_1.REQUEST_TIMEOUT_MS)));
        }
        catch (err) {
            return {
                error: `API call error: ${String(err)}`,
                tokenUsage: {
                    total: 0,
                    prompt: 0,
                    completion: 0,
                },
            };
        }
        logger_1.default.debug(`\tAzure OpenAI API response (embeddings): ${JSON.stringify(data)}`);
        try {
            const embedding = data?.data?.[0]?.embedding;
            if (!embedding) {
                throw new Error('No embedding returned');
            }
            const ret = {
                embedding,
                tokenUsage: cached
                    ? { cached: data.usage.total_tokens, total: data.usage.total_tokens }
                    : {
                        total: data.usage.total_tokens,
                        prompt: data.usage.prompt_tokens,
                        completion: data.usage.completion_tokens,
                    },
            };
            return ret;
        }
        catch (err) {
            return {
                error: `API response error: ${String(err)}: ${JSON.stringify(data)}`,
                tokenUsage: cached
                    ? {
                        cached: data.usage.total_tokens,
                        total: data.usage.total_tokens,
                    }
                    : {
                        total: data?.usage?.total_tokens,
                        prompt: data?.usage?.prompt_tokens,
                        completion: data?.usage?.completion_tokens,
                    },
            };
        }
    }
}
exports.AzureOpenAiEmbeddingProvider = AzureOpenAiEmbeddingProvider;
class AzureOpenAiCompletionProvider extends AzureOpenAiGenericProvider {
    async callApi(prompt, context, callApiOptions) {
        const apiKey = await this.getApiKey();
        if (!apiKey) {
            throw new Error('Azure OpenAI API key is not set. Set AZURE_OPENAI_API_KEY environment variable or pass it as an argument to the constructor.');
        }
        if (!this.getApiBaseUrl()) {
            throw new Error('Azure OpenAI API host must be set');
        }
        let stop;
        try {
            stop = process.env.OPENAI_STOP
                ? JSON.parse(process.env.OPENAI_STOP)
                : this.config?.stop || ['<|im_end|>', '<|endoftext|>'];
        }
        catch (err) {
            throw new Error(`OPENAI_STOP is not a valid JSON string: ${err}`);
        }
        const body = {
            model: this.deploymentName,
            prompt,
            max_tokens: parseInt(process.env.OPENAI_MAX_TOKENS || '1024'),
            temperature: this.config.temperature ?? parseFloat(process.env.OPENAI_TEMPERATURE || '0'),
            top_p: this.config.top_p ?? parseFloat(process.env.OPENAI_TOP_P || '1'),
            presence_penalty: this.config.presence_penalty ?? parseFloat(process.env.OPENAI_PRESENCE_PENALTY || '0'),
            frequency_penalty: this.config.frequency_penalty ?? parseFloat(process.env.OPENAI_FREQUENCY_PENALTY || '0'),
            best_of: this.config.best_of ?? parseInt(process.env.OPENAI_BEST_OF || '1'),
            ...(this.config.deployment_id ? { deployment_id: this.config.deployment_id } : {}),
            ...(this.config.dataSources ? { dataSources: this.config.dataSources } : {}),
            ...(this.config.response_format ? { response_format: this.config.response_format } : {}),
            ...(callApiOptions?.includeLogProbs ? { logprobs: callApiOptions.includeLogProbs } : {}),
            ...(stop ? { stop } : {}),
            ...(this.config.passthrough || {}),
        };
        logger_1.default.debug(`Calling Azure OpenAI API: ${JSON.stringify(body)}`);
        let data, cached = false;
        try {
            ({ data, cached } = (await (0, cache_1.fetchWithCache)(`${this.getApiBaseUrl()}/openai/deployments/${this.deploymentName}/completions?api-version=${this.config.apiVersion || '2023-12-01-preview'}`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'api-key': apiKey,
                },
                body: JSON.stringify(body),
            }, shared_1.REQUEST_TIMEOUT_MS)));
        }
        catch (err) {
            return {
                error: `API call error: ${String(err)}`,
            };
        }
        logger_1.default.debug(`\tAzure OpenAI API response: ${JSON.stringify(data)}`);
        try {
            return {
                output: data.choices[0].text,
                tokenUsage: cached
                    ? { cached: data.usage.total_tokens, total: data.usage.total_tokens }
                    : {
                        total: data.usage.total_tokens,
                        prompt: data.usage.prompt_tokens,
                        completion: data.usage.completion_tokens,
                    },
            };
        }
        catch (err) {
            return {
                error: `API response error: ${String(err)}: ${JSON.stringify(data)}`,
            };
        }
    }
}
exports.AzureOpenAiCompletionProvider = AzureOpenAiCompletionProvider;
class AzureOpenAiChatCompletionProvider extends AzureOpenAiGenericProvider {
    async callApi(prompt, context, callApiOptions) {
        const apiKey = await this.getApiKey();
        if (!apiKey) {
            throw new Error('Azure OpenAI API key is not set. Set the AZURE_OPENAI_API_KEY environment variable or add `apiKey` to the provider config.');
        }
        if (!this.getApiBaseUrl()) {
            throw new Error('Azure OpenAI API host must be set');
        }
        const messages = (0, shared_1.parseChatPrompt)(prompt, [{ role: 'user', content: prompt }]);
        let stop;
        try {
            stop = process.env.OPENAI_STOP ? JSON.parse(process.env.OPENAI_STOP) : this.config?.stop;
        }
        catch (err) {
            throw new Error(`OPENAI_STOP is not a valid JSON string: ${err}`);
        }
        const body = {
            model: this.deploymentName,
            messages: messages,
            max_tokens: parseInt(process.env.OPENAI_MAX_TOKENS || '1024'),
            temperature: this.config.temperature ?? parseFloat(process.env.OPENAI_TEMPERATURE || '0'),
            top_p: this.config.top_p ?? parseFloat(process.env.OPENAI_TOP_P || '1'),
            presence_penalty: this.config.presence_penalty ?? parseFloat(process.env.OPENAI_PRESENCE_PENALTY || '0'),
            frequency_penalty: this.config.frequency_penalty ?? parseFloat(process.env.OPENAI_FREQUENCY_PENALTY || '0'),
            functions: this.config.functions || undefined,
            function_call: this.config.function_call || undefined,
            ...(this.config.deployment_id ? { deployment_id: this.config.deployment_id } : {}),
            ...(this.config.dataSources ? { dataSources: this.config.dataSources } : {}),
            ...(this.config.response_format ? { response_format: this.config.response_format } : {}),
            ...(callApiOptions?.includeLogProbs ? { logprobs: callApiOptions.includeLogProbs } : {}),
            ...(this.config.stop ? { stop: this.config.stop } : {}),
            ...(this.config.passthrough || {}),
        };
        logger_1.default.debug(`Calling Azure OpenAI API: ${JSON.stringify(body)}`);
        let data, cached = false;
        try {
            const url = this.config.dataSources
                ? `${this.getApiBaseUrl()}/openai/deployments/${this.deploymentName}/extensions/chat/completions?api-version=${this.config.apiVersion || '2023-12-01-preview'}`
                : `${this.getApiBaseUrl()}/openai/deployments/${this.deploymentName}/chat/completions?api-version=${this.config.apiVersion || '2023-12-01-preview'}`;
            ({ data, cached } = (await (0, cache_1.fetchWithCache)(url, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'api-key': apiKey,
                },
                body: JSON.stringify(body),
            }, shared_1.REQUEST_TIMEOUT_MS)));
        }
        catch (err) {
            return {
                error: `API call error: ${String(err)}`,
            };
        }
        logger_1.default.debug(`\tAzure OpenAI API response: ${JSON.stringify(data)}`);
        try {
            if (data.error) {
                return {
                    error: `API response error: ${data.error.code} ${data.error.message}`,
                };
            }
            const message = this.config.dataSources
                ? data.choices[0].messages.find((msg) => msg.role === 'assistant')
                : data.choices[0].message;
            const output = message.content == null ? message.function_call : message.content;
            const logProbs = data.choices[0].logprobs?.content?.map((logProbObj) => logProbObj.logprob);
            return {
                output,
                tokenUsage: cached
                    ? { cached: data.usage?.total_tokens, total: data?.usage?.total_tokens }
                    : {
                        total: data.usage?.total_tokens,
                        prompt: data.usage?.prompt_tokens,
                        completion: data.usage?.completion_tokens,
                    },
                cached,
                logProbs,
            };
        }
        catch (err) {
            return {
                error: `API response error: ${String(err)}: ${JSON.stringify(data)}`,
            };
        }
    }
}
exports.AzureOpenAiChatCompletionProvider = AzureOpenAiChatCompletionProvider;
//# sourceMappingURL=azureopenai.js.map